{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNHEV+OcmWjo9AsPycZfnps",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrianacupp/NLP_with_Transformers/blob/main/BART_Relation_Classification_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data"
      ],
      "metadata": {
        "id": "KuBkK88fUQ8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "PqRpd6xwbeU_",
        "outputId": "bac7670e-d76e-4b75-b989-abd68290004d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-57b74b7a-5561-4880-adcc-cdd7e31ab2c2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-57b74b7a-5561-4880-adcc-cdd7e31ab2c2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"adracupp\",\"key\":\"e74d1222705292f7c525d7e2a435b34f\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Series of commands to set-up for download\n",
        "\n",
        "!ls -lha kaggle.json\n",
        "!pip install -q kaggle # installing the kaggle package\n",
        "!mkdir -p ~/.kaggle # creating .kaggle folder where the key should be placed\n",
        "!cp kaggle.json ~/.kaggle/ # move the key to the folder\n",
        "!pwd # checking the present working directory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0jv1l6ZLJir",
        "outputId": "d29b38d0-0689-4273-f8f8-28dbf9501c15"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 64 Aug  8 09:59 kaggle.json\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. giving rw access (if 401-nathorized)\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "tFeIQAjNLMzz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Sanity check if able to access kaggle\n",
        "!kaggle datasets list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAOeZXBzLOd6",
        "outputId": "f3b3f93f-3eb4-4367-9b94-842da665c449"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                        title                                               size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "---------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "myrios/cost-of-living-index-by-country-by-number-2024      Cost of Living Index by Country                      3KB  2024-07-19 06:25:42           2244         29  1.0              \n",
            "waqi786/cats-dataset                                       🐾 Cats Dataset                                       6KB  2024-07-31 06:12:49           2108         43  1.0              \n",
            "muhammadehsan000/olympic-historical-dataset-1896-2020      Olympic Historical Dataset (1896 - 2022)            27MB  2024-08-06 16:46:08           1141         26  1.0              \n",
            "abhayayare/employee-data-simulation-it-industry            Employee Data Simulation: IT Industry                4KB  2024-07-21 15:26:17           2286         35  1.0              \n",
            "ahmedmohamedibrahim1/coffee-shop-sales-dataset             Coffee Shop Sales Dataset                           17MB  2024-08-05 10:43:15           1334         22  0.8235294        \n",
            "ihelon/coffee-sales                                        Coffee Sales                                        13KB  2024-08-01 07:55:34          10172        156  1.0              \n",
            "rabieelkharoua/students-performance-dataset                📚 Students Performance Dataset 📚                    66KB  2024-06-12 23:09:20          28232        546  1.0              \n",
            "patricklford/global-ev-sales-2010-2024                     Global EV Sales: 2010-2024                          83KB  2024-07-19 13:40:22           2849         38  1.0              \n",
            "anthonytherrien/depression-dataset                         Depression Dataset                                   9MB  2024-07-19 20:42:08           1506         29  1.0              \n",
            "datazng/shopping-mall-customer-data-segmentation-analysis  Shopping Mall Customer Data Segmentation Analysis    6MB  2024-08-04 20:36:31           1167         33  0.88235295       \n",
            "waqi786/mobile-sales-dataset                               Mobile Sales Dataset 📱                              58KB  2024-07-26 11:03:16           2029         35  1.0              \n",
            "waqi786/top-games-dataset                                  Top Games Dataset 🎮📊                                77KB  2024-08-02 11:27:16           1240         24  1.0              \n",
            "priyamchoksi/credit-card-transactions-dataset              Credit Card Transactions Dataset                   145MB  2024-07-23 00:31:47           1604         33  1.0              \n",
            "rasikasrimal/covid-19-confirmed-cases                      covid-19 confirmed cases                            30KB  2024-07-18 12:04:09           1367         27  1.0              \n",
            "ashishjangra27/doodle-dataset                              Doodle Dataset                                       5GB  2024-08-04 04:27:10            433         22  1.0              \n",
            "nelgiriyewithana/most-streamed-spotify-songs-2024          Most Streamed Spotify Songs 2024                   496KB  2024-06-15 18:50:51          20250        385  1.0              \n",
            "marius2303/nissan-all-models-price-prediction-dataset      Nissan All Models Price Prediction Dataset         811KB  2024-07-27 11:50:10           1172         26  1.0              \n",
            "waqi786/1000-richest-people-in-the-world                   1000 Richest People in the World                     8KB  2024-07-28 05:39:38           1273         32  1.0              \n",
            "jenilhareshbhaighori/smartphone-data-analysis-using        SmartPhone  Data analysis using                    785KB  2024-07-31 06:14:47            726         24  0.9411765        \n",
            "mbsoroush/mobile-price-range                               Mobile Price Range                                  71KB  2024-07-29 08:05:56           1159         26  1.0              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d daishinkan002/new-york-times-relation-extraction-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6dcuiAWLRpK",
        "outputId": "e5e7a769-dda6-46c8-abbd-4cc7eca755f9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/daishinkan002/new-york-times-relation-extraction-dataset\n",
            "License(s): unknown\n",
            "Downloading new-york-times-relation-extraction-dataset.zip to /content\n",
            " 55% 5.00M/9.02M [00:00<00:00, 30.7MB/s]\n",
            "100% 9.02M/9.02M [00:00<00:00, 47.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPaJpGaoLT2R",
        "outputId": "d824cc05-b939-4b9f-ef5a-c410b8fe559b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoMx34DJLaOt",
        "outputId": "725adf2f-2d28-4120-8468-20d6b2755d57"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 9.1M\n",
            "drwxr-xr-x 1 root root 4.0K Aug  8 10:00 .\n",
            "drwxr-xr-x 1 root root 4.0K Aug  8 08:41 ..\n",
            "drwxr-xr-x 4 root root 4.0K Aug  6 13:32 .config\n",
            "drwxr-xr-x 2 root root 4.0K Aug  8 08:44 dataset\n",
            "drwx------ 6 root root 4.0K Aug  8 08:46 drive\n",
            "drwxr-xr-x 2 root root 4.0K Aug  8 09:51 .ipynb_checkpoints\n",
            "-rw-r--r-- 1 root root   64 Aug  8 09:59 kaggle.json\n",
            "-rw-r--r-- 1 root root 9.1M Jul 31  2021 new-york-times-relation-extraction-dataset.zip\n",
            "drwxr-xr-x 1 root root 4.0K Aug  6 13:32 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -f new-york-times-relation-extraction-dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpLCCn8KbG8R",
        "outputId": "7ab55e4a-9d97-4e77-9216-62d5830f640d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  new-york-times-relation-extraction-dataset.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract relations from a JSON object\n",
        "def extract_relations(json_line):\n",
        "    relations = []\n",
        "    sent_text = json_line['sentText']\n",
        "    for relation in json_line['relationMentions']:\n",
        "        em1_text = relation['em1Text']\n",
        "        em2_text = relation['em2Text']\n",
        "        label = relation['label']\n",
        "        relations.append((sent_text, em1_text, em2_text, label))\n",
        "    return relations"
      ],
      "metadata": {
        "id": "hLGZxbIOLgIC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Define the file path\n",
        "input_file = 'dataset/train.json'\n",
        "\n",
        "# Initialize a list to hold the data\n",
        "data = []\n",
        "\n",
        "# Initialize a counter for the number of lines processed\n",
        "count = 0\n",
        "\n",
        "# Read the JSON file\n",
        "with open(input_file, 'r') as file:\n",
        "    for line in file:\n",
        "        json_line = json.loads(line)  # Load JSON object from the line\n",
        "        relations = extract_relations(json_line)  # Extract relations\n",
        "        data.extend(relations)  # Add extracted relations to the data list\n",
        "        count += 1  # Increment the counter"
      ],
      "metadata": {
        "id": "yz-M13AsLjm9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of lines processed and the first few extracted relations\n",
        "print(f\"Processed {count} lines.\")\n",
        "print(f\"First few extracted relations: {data[:5]}\")"
      ],
      "metadata": {
        "id": "Xm5U3AwzLpLv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f6c005e-f20b-43fe-a87b-53ea985faad5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 56196 lines.\n",
            "First few extracted relations: [('Massachusetts ASTON MAGNA Great Barrington ; also at Bard College , Annandale-on-Hudson , N.Y. , July 1-Aug .', 'Annandale-on-Hudson', 'Bard College', '/location/location/contains'), ('North Carolina EASTERN MUSIC FESTIVAL Greensboro , June 25-July 30 .', 'North Carolina', 'Greensboro', '/location/location/contains'), (\"It will be the final movie credited to Debra Hill , a film producer and native of Haddonfield , who produced '' Halloween '' and was considered a pioneering woman in film .\", 'Debra Hill', 'Haddonfield', '/people/person/place_of_birth'), (\"In a 3-0 victory over the Crew on Saturday in Columbus , Ohio , goalkeeper Zach Wells stopped Kyle Martino 's penalty kick , only the third unsuccessful penalty in 20 attempts in M.L.S. this season .\", 'Ohio', 'Columbus', '/location/location/contains'), (\"The United States ambassador to Mexico , Tony Garza , said in a statement that he had directed the American Consulate in Nuevo Laredo to reopen on Monday , a week after he ordered it closed because of '' rampant violence '' along the northern border , including a gun battle in the city in which warring drug gangs used bazookas .\", 'Mexico', 'Nuevo Laredo', '/location/location/contains')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Convert the extracted data to a pandas DataFrame\n",
        "df = pd.DataFrame(data, columns=['sentence', 'entity1', 'entity2', 'label'])\n",
        "\n",
        "output_path = '/content/drive/MyDrive/Colab Notebooks/extracted_relations.csv'\n",
        "\n",
        "df.to_csv(output_path, index=False)\n"
      ],
      "metadata": {
        "id": "BHJIvgKlLrnP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b1a0f59-2d1f-4fb6-877f-e44705708641"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "kwtoO5uyLvA9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b2053ae-5480-4532-8595-5ef152756d0e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            sentence              entity1  \\\n",
            "0  Massachusetts ASTON MAGNA Great Barrington ; a...  Annandale-on-Hudson   \n",
            "1  North Carolina EASTERN MUSIC FESTIVAL Greensbo...       North Carolina   \n",
            "2  It will be the final movie credited to Debra H...           Debra Hill   \n",
            "3  In a 3-0 victory over the Crew on Saturday in ...                 Ohio   \n",
            "4  The United States ambassador to Mexico , Tony ...               Mexico   \n",
            "\n",
            "        entity2                          label  \n",
            "0  Bard College    /location/location/contains  \n",
            "1    Greensboro    /location/location/contains  \n",
            "2   Haddonfield  /people/person/place_of_birth  \n",
            "3      Columbus    /location/location/contains  \n",
            "4  Nuevo Laredo    /location/location/contains  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 94222 entries, 0 to 94221\n",
            "Data columns (total 4 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   sentence  94222 non-null  object\n",
            " 1   entity1   94222 non-null  object\n",
            " 2   entity2   94222 non-null  object\n",
            " 3   label     94222 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 2.9+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Change the first letter to an empty string in the label column\n",
        "df['label'] = df['label'].str[1:]\n",
        "df['label'] = df['label'].str.replace('/', '_')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "DqXgLLdCL58X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "772f462a-0c8a-44b9-d605-76f7cbd003a6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence              entity1  \\\n",
              "0  Massachusetts ASTON MAGNA Great Barrington ; a...  Annandale-on-Hudson   \n",
              "1  North Carolina EASTERN MUSIC FESTIVAL Greensbo...       North Carolina   \n",
              "2  It will be the final movie credited to Debra H...           Debra Hill   \n",
              "3  In a 3-0 victory over the Crew on Saturday in ...                 Ohio   \n",
              "4  The United States ambassador to Mexico , Tony ...               Mexico   \n",
              "\n",
              "        entity2                         label  \n",
              "0  Bard College    location_location_contains  \n",
              "1    Greensboro    location_location_contains  \n",
              "2   Haddonfield  people_person_place_of_birth  \n",
              "3      Columbus    location_location_contains  \n",
              "4  Nuevo Laredo    location_location_contains  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b65f5a3-0f30-4c63-9d44-e13db5b0eef6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>entity1</th>\n",
              "      <th>entity2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Massachusetts ASTON MAGNA Great Barrington ; a...</td>\n",
              "      <td>Annandale-on-Hudson</td>\n",
              "      <td>Bard College</td>\n",
              "      <td>location_location_contains</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>North Carolina EASTERN MUSIC FESTIVAL Greensbo...</td>\n",
              "      <td>North Carolina</td>\n",
              "      <td>Greensboro</td>\n",
              "      <td>location_location_contains</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It will be the final movie credited to Debra H...</td>\n",
              "      <td>Debra Hill</td>\n",
              "      <td>Haddonfield</td>\n",
              "      <td>people_person_place_of_birth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In a 3-0 victory over the Crew on Saturday in ...</td>\n",
              "      <td>Ohio</td>\n",
              "      <td>Columbus</td>\n",
              "      <td>location_location_contains</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The United States ambassador to Mexico , Tony ...</td>\n",
              "      <td>Mexico</td>\n",
              "      <td>Nuevo Laredo</td>\n",
              "      <td>location_location_contains</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b65f5a3-0f30-4c63-9d44-e13db5b0eef6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4b65f5a3-0f30-4c63-9d44-e13db5b0eef6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4b65f5a3-0f30-4c63-9d44-e13db5b0eef6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d178cbb7-670c-46e9-9741-5eca52843888\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d178cbb7-670c-46e9-9741-5eca52843888')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d178cbb7-670c-46e9-9741-5eca52843888 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 94222,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 54643,\n        \"samples\": [\n          \"Milde said he received a commitment recently from Mizuki Noguchi of Japan , who won the women 's gold medal in Athens and won Berlin last year in 2:19:12 . ''\",\n          \"A12 U.S. and France Press Syria The United States and France circulated a draft Security Council resolution ordering Syria to cooperate with the United Nations investigation of the assassination of former Prime Minister Rafik Hariri of Lebanon and threatening sanctions if it did not do so .\",\n          \"Councilman David I. Weprin of Queens , the chairman of the Council 's Finance Committee , said , '' With Albany looking at change , we thought this was the next step for transparency in the budget process for New York . ''\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"entity1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7905,\n        \"samples\": [\n          \"Houston Astros\",\n          \"Flatbush\",\n          \"Cobble Hill\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"entity2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7230,\n        \"samples\": [\n          \"Nagasaki\",\n          \"Perfume River\",\n          \"Cameron Parish\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"people_person_children\",\n          \"sports_sports_team_location_teams\",\n          \"location_location_contains\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the unique labels in the label column\n",
        "unique_labels = df['label'].unique()\n",
        "sorted(unique_labels)"
      ],
      "metadata": {
        "id": "QxRuPAuyMJL-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d3a42fb-7f2e-4fb7-ae91-9f47a35dbb3d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['business_company_advisors',\n",
              " 'business_company_founders',\n",
              " 'business_company_industry',\n",
              " 'business_company_major_shareholders',\n",
              " 'business_company_place_founded',\n",
              " 'business_company_shareholder_major_shareholder_of',\n",
              " 'business_person_company',\n",
              " 'location_administrative_division_country',\n",
              " 'location_country_administrative_divisions',\n",
              " 'location_country_capital',\n",
              " 'location_location_contains',\n",
              " 'location_neighborhood_neighborhood_of',\n",
              " 'people_deceased_person_place_of_death',\n",
              " 'people_ethnicity_geographic_distribution',\n",
              " 'people_ethnicity_people',\n",
              " 'people_person_children',\n",
              " 'people_person_ethnicity',\n",
              " 'people_person_nationality',\n",
              " 'people_person_place_lived',\n",
              " 'people_person_place_of_birth',\n",
              " 'people_person_profession',\n",
              " 'people_person_religion',\n",
              " 'sports_sports_team_location',\n",
              " 'sports_sports_team_location_teams']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "9XeezY0WMNmZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3af324a-ac9f-4c8a-b86e-9f16f28a178b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sentence', 'entity1', 'entity2', 'label'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentence_length'] = df['sentence'].apply(lambda x: len(x.split()))\n",
        "avg_sentence_length = df['sentence_length'].mean()\n",
        "print(f\"Average sentence length: {avg_sentence_length} words\")"
      ],
      "metadata": {
        "id": "MRcMVSgDM6vx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "222730c5-4ea0-48ec-cc83-50bd0dd6a8d0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average sentence length: 39.01351064507227 words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess"
      ],
      "metadata": {
        "id": "6FjfTJ6PK-SE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BartTokenizer, AutoModelForSeq2SeqLM, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "7fkYA1f9K9Jr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "8UvVSiWfLHrl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the tokenizer\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "_XN9gxtVLLUv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "481dd833-fec6-4a15-c2e6-5c181dc1746c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create label encoder\n",
        "label_encoder = {label: i for i, label in enumerate(df['label'].unique())}\n",
        "label_decoder = {i: label for label, i in label_encoder.items()}"
      ],
      "metadata": {
        "id": "V9-flNpnLfgP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the maximum length of the tokenized labels\n",
        "label_lengths = [len(tokenizer.encode(label, add_special_tokens=True)) for label in df['label'].unique()]\n",
        "max_label_length = max(label_lengths)\n",
        "print(f\"Maximum label length: {max_label_length}\")"
      ],
      "metadata": {
        "id": "ypNBE9GRNmOK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da9a6092-a1d0-4eb9-9dc6-918295242220"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum label length: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# in BART model the labels (relationship types) are treated as sequences (strings)\n",
        "# that need to be tokenized just like the input sentence\n",
        "def preprocess_data(row):\n",
        "    sentence = row['sentence']\n",
        "    label = row['label']\n",
        "\n",
        "    # Tokenize input sentence\n",
        "    encoded_sentence = tokenizer(\n",
        "        sentence,\n",
        "        add_special_tokens=True,\n",
        "        max_length=128,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    ).to(device)\n",
        "\n",
        "    # Encode the label as the target sequence\n",
        "    encoded_label = tokenizer(\n",
        "        label,\n",
        "        add_special_tokens=True,\n",
        "        max_length=15,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    ).to(device)\n",
        "\n",
        "    return {\n",
        "        'input_ids': encoded_sentence['input_ids'].squeeze(),\n",
        "        'attention_mask': encoded_sentence['attention_mask'].squeeze(),\n",
        "        'labels': encoded_label['input_ids'].squeeze()\n",
        "    }\n",
        "  #labels: sequence of token IDs representing the target relationship label"
      ],
      "metadata": {
        "id": "LcPGnXJSLvih"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#apply preprocess to dataset\n",
        "train_data = train_df.apply(preprocess_data, axis=1).tolist()\n",
        "val_data = val_df.apply(preprocess_data, axis=1).tolist()"
      ],
      "metadata": {
        "id": "LhP7VDXJMIqQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create custom dataset class\n",
        "class RelationshipDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]"
      ],
      "metadata": {
        "id": "SRQm3kYcNI9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset and dataloader\n",
        "train_dataset = RelationshipDataset(train_data)\n",
        "val_dataset = RelationshipDataset(val_data)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=24, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "aQK1Lc2AOcKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Model"
      ],
      "metadata": {
        "id": "Sb5FGMyZOp2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM"
      ],
      "metadata": {
        "id": "QVPXjWNJOnXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RelationshipExtractionModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.bart = AutoModelForSeq2SeqLM.from_pretrained('facebook/bart-large')\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels):\n",
        "        outputs = self.bart(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "        return outputs.loss, outputs.logits"
      ],
      "metadata": {
        "id": "VyFc1eEjOurH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RelationshipExtractionModel().to(device)"
      ],
      "metadata": {
        "id": "Cyo2f3VxOzjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training configuration\n",
        "num_epochs = 7\n",
        "learning_rate = 2.5e-5\n",
        "gradient_accumulation_steps = 1\n",
        "max_grad_norm = 1.0"
      ],
      "metadata": {
        "id": "RhaojPviPDhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=0.1)\n",
        "total_steps = len(train_dataloader) * num_epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=8000,\n",
        "    num_training_steps=total_steps\n",
        ")"
      ],
      "metadata": {
        "id": "jFHaLEemPK1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop"
      ],
      "metadata": {
        "id": "v1COS4HePmmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def evaluate(model, dataloader, device, tokenizer, label_decoder):\n",
        "    model.eval()\n",
        "    total_preds = []\n",
        "    total_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Generate predictions\n",
        "            outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
        "            preds = [tokenizer.decode(g, skip_special_tokens=True) for g in outputs]\n",
        "            labels = [tokenizer.decode(l, skip_special_tokens=True) for l in labels]\n",
        "\n",
        "            # Collect predictions and labels\n",
        "            total_preds.extend(preds)\n",
        "            total_labels.extend(labels)\n",
        "\n",
        "    # Convert labels and predictions to a common format\n",
        "    total_preds = [label_decoder.get(p, p) for p in total_preds]\n",
        "    total_labels = [label_decoder.get(l, l) for l in total_labels]\n",
        "\n",
        "    # Calculate metrics\n",
        "    precision = precision_score(total_labels, total_preds, average='weighted')\n",
        "    recall = recall_score(total_labels, total_preds, average='weighted')\n",
        "    f1 = f1_score(total_labels, total_preds, average='weighted')\n",
        "\n",
        "    return precision, recall, f1\n"
      ],
      "metadata": {
        "id": "4w23kB2OPful"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "        # Access loss from the tuple\n",
        "        if isinstance(outputs, tuple):\n",
        "            loss = outputs[0]  # The first element of the tuple is the loss\n",
        "        else:\n",
        "            loss = outputs.loss  # For a ModelOutput object\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        progress_bar.set_postfix({'loss': total_loss / (progress_bar.n + 1)})\n",
        "\n",
        "    # Calculate validation metrics\n",
        "    val_precision, val_recall, val_f1 = evaluate(model, val_dataloader, device, tokenizer, label_decoder)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} completed.\")\n",
        "    print(f\"Validation Precision: {val_precision:.4f}\")\n",
        "    print(f\"Validation Recall: {val_recall:.4f}\")\n",
        "    print(f\"Validation F1 Score: {val_f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "Y4QRzi3yR5ee"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}