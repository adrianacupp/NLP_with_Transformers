{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2485002,"sourceType":"datasetVersion","datasetId":1504204}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Extract and read dataset","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) \n# will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/new-york-times-relation-extraction-dataset'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-12T06:19:57.739699Z","iopub.execute_input":"2024-08-12T06:19:57.740301Z","iopub.status.idle":"2024-08-12T06:19:58.718501Z","shell.execute_reply.started":"2024-08-12T06:19:57.740268Z","shell.execute_reply":"2024-08-12T06:19:58.717399Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/new-york-times-relation-extraction-dataset/dataset/train.json\n/kaggle/input/new-york-times-relation-extraction-dataset/dataset/test.json\n/kaggle/input/new-york-times-relation-extraction-dataset/dataset/valid.json\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function to extract relations from a JSON object\ndef extract_relations(json_line):\n    relations = []\n    sent_text = json_line['sentText']\n    for relation in json_line['relationMentions']:\n        em1_text = relation['em1Text']\n        em2_text = relation['em2Text']\n        label = relation['label']\n        relations.append((sent_text, em1_text, em2_text, label))\n    return relations","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:20:03.707932Z","iopub.execute_input":"2024-08-12T06:20:03.708248Z","iopub.status.idle":"2024-08-12T06:20:03.714386Z","shell.execute_reply.started":"2024-08-12T06:20:03.708223Z","shell.execute_reply":"2024-08-12T06:20:03.713268Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import json\n\n# Define the file path\ninput_file = '/kaggle/input/new-york-times-relation-extraction-dataset/dataset/train.json'\n\n# Initialize a list to hold the data\ndata = []\n\n# Initialize a counter for the number of lines processed\ncount = 0\n\n# Read the JSON file\nwith open(input_file, 'r') as file:\n    for line in file:\n        json_line = json.loads(line)  # Load JSON object from the line\n        relations = extract_relations(json_line)  # Extract relations\n        data.extend(relations)  # Add extracted relations to the data list\n        count += 1  # Increment the counter","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:20:12.582899Z","iopub.execute_input":"2024-08-12T06:20:12.583554Z","iopub.status.idle":"2024-08-12T06:20:13.707529Z","shell.execute_reply.started":"2024-08-12T06:20:12.583510Z","shell.execute_reply":"2024-08-12T06:20:13.706751Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Print the number of lines processed and the first few extracted relations\nprint(f\"Processed {count} lines.\")\nprint(f\"First few extracted relations: {data[:5]}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:20:18.747773Z","iopub.execute_input":"2024-08-12T06:20:18.748440Z","iopub.status.idle":"2024-08-12T06:20:18.753282Z","shell.execute_reply.started":"2024-08-12T06:20:18.748406Z","shell.execute_reply":"2024-08-12T06:20:18.752374Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Processed 56196 lines.\nFirst few extracted relations: [('Massachusetts ASTON MAGNA Great Barrington ; also at Bard College , Annandale-on-Hudson , N.Y. , July 1-Aug .', 'Annandale-on-Hudson', 'Bard College', '/location/location/contains'), ('North Carolina EASTERN MUSIC FESTIVAL Greensboro , June 25-July 30 .', 'North Carolina', 'Greensboro', '/location/location/contains'), (\"It will be the final movie credited to Debra Hill , a film producer and native of Haddonfield , who produced '' Halloween '' and was considered a pioneering woman in film .\", 'Debra Hill', 'Haddonfield', '/people/person/place_of_birth'), (\"In a 3-0 victory over the Crew on Saturday in Columbus , Ohio , goalkeeper Zach Wells stopped Kyle Martino 's penalty kick , only the third unsuccessful penalty in 20 attempts in M.L.S. this season .\", 'Ohio', 'Columbus', '/location/location/contains'), (\"The United States ambassador to Mexico , Tony Garza , said in a statement that he had directed the American Consulate in Nuevo Laredo to reopen on Monday , a week after he ordered it closed because of '' rampant violence '' along the northern border , including a gun battle in the city in which warring drug gangs used bazookas .\", 'Mexico', 'Nuevo Laredo', '/location/location/contains')]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convert the extracted data to a pandas DataFrame\ndf = pd.DataFrame(data, columns=['sentence', 'entity1', 'entity2', 'label'])","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:20:22.031478Z","iopub.execute_input":"2024-08-12T06:20:22.032198Z","iopub.status.idle":"2024-08-12T06:20:22.070985Z","shell.execute_reply.started":"2024-08-12T06:20:22.032162Z","shell.execute_reply":"2024-08-12T06:20:22.070072Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(df.head(1))\nprint(df.info())","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:20:33.883966Z","iopub.execute_input":"2024-08-12T06:20:33.884310Z","iopub.status.idle":"2024-08-12T06:20:33.935483Z","shell.execute_reply.started":"2024-08-12T06:20:33.884280Z","shell.execute_reply":"2024-08-12T06:20:33.934467Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"                                            sentence              entity1  \\\n0  Massachusetts ASTON MAGNA Great Barrington ; a...  Annandale-on-Hudson   \n\n        entity2                        label  \n0  Bard College  /location/location/contains  \n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 94222 entries, 0 to 94221\nData columns (total 4 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   sentence  94222 non-null  object\n 1   entity1   94222 non-null  object\n 2   entity2   94222 non-null  object\n 3   label     94222 non-null  object\ndtypes: object(4)\nmemory usage: 2.9+ MB\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"#Change the first letter to an empty string in the label column\ndf['label'] = df['label'].str[1:]\ndf['label'] = df['label'].str.replace('/', '_')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:20:47.362350Z","iopub.execute_input":"2024-08-12T06:20:47.363175Z","iopub.status.idle":"2024-08-12T06:20:47.459545Z","shell.execute_reply.started":"2024-08-12T06:20:47.363142Z","shell.execute_reply":"2024-08-12T06:20:47.458727Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                            sentence              entity1  \\\n0  Massachusetts ASTON MAGNA Great Barrington ; a...  Annandale-on-Hudson   \n1  North Carolina EASTERN MUSIC FESTIVAL Greensbo...       North Carolina   \n2  It will be the final movie credited to Debra H...           Debra Hill   \n3  In a 3-0 victory over the Crew on Saturday in ...                 Ohio   \n4  The United States ambassador to Mexico , Tony ...               Mexico   \n\n        entity2                         label  \n0  Bard College    location_location_contains  \n1    Greensboro    location_location_contains  \n2   Haddonfield  people_person_place_of_birth  \n3      Columbus    location_location_contains  \n4  Nuevo Laredo    location_location_contains  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>entity1</th>\n      <th>entity2</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Massachusetts ASTON MAGNA Great Barrington ; a...</td>\n      <td>Annandale-on-Hudson</td>\n      <td>Bard College</td>\n      <td>location_location_contains</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>North Carolina EASTERN MUSIC FESTIVAL Greensbo...</td>\n      <td>North Carolina</td>\n      <td>Greensboro</td>\n      <td>location_location_contains</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>It will be the final movie credited to Debra H...</td>\n      <td>Debra Hill</td>\n      <td>Haddonfield</td>\n      <td>people_person_place_of_birth</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>In a 3-0 victory over the Crew on Saturday in ...</td>\n      <td>Ohio</td>\n      <td>Columbus</td>\n      <td>location_location_contains</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The United States ambassador to Mexico , Tony ...</td>\n      <td>Mexico</td>\n      <td>Nuevo Laredo</td>\n      <td>location_location_contains</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Print the unique labels in the label column\nunique_labels = df['label'].unique()\nsorted(unique_labels)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:20:56.889315Z","iopub.execute_input":"2024-08-12T06:20:56.889976Z","iopub.status.idle":"2024-08-12T06:20:56.906040Z","shell.execute_reply.started":"2024-08-12T06:20:56.889941Z","shell.execute_reply":"2024-08-12T06:20:56.905184Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"['business_company_advisors',\n 'business_company_founders',\n 'business_company_industry',\n 'business_company_major_shareholders',\n 'business_company_place_founded',\n 'business_company_shareholder_major_shareholder_of',\n 'business_person_company',\n 'location_administrative_division_country',\n 'location_country_administrative_divisions',\n 'location_country_capital',\n 'location_location_contains',\n 'location_neighborhood_neighborhood_of',\n 'people_deceased_person_place_of_death',\n 'people_ethnicity_geographic_distribution',\n 'people_ethnicity_people',\n 'people_person_children',\n 'people_person_ethnicity',\n 'people_person_nationality',\n 'people_person_place_lived',\n 'people_person_place_of_birth',\n 'people_person_profession',\n 'people_person_religion',\n 'sports_sports_team_location',\n 'sports_sports_team_location_teams']"},"metadata":{}}]},{"cell_type":"code","source":"#filter similar labels and compare\ndf[df['label'] == 'location_administrative_division_country'].iloc[0]","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:21:22.134371Z","iopub.execute_input":"2024-08-12T06:21:22.135040Z","iopub.status.idle":"2024-08-12T06:21:22.162465Z","shell.execute_reply.started":"2024-08-12T06:21:22.135004Z","shell.execute_reply":"2024-08-12T06:21:22.161651Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"sentence    Quebec , Canada 's second most populous provin...\nentity1                                               Ontario\nentity2                                                Canada\nlabel                location_administrative_division_country\nName: 11, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"df[df['label'] == 'location_country_administrative_divisions'].iloc[0]","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:21:38.354480Z","iopub.execute_input":"2024-08-12T06:21:38.354826Z","iopub.status.idle":"2024-08-12T06:21:38.380669Z","shell.execute_reply.started":"2024-08-12T06:21:38.354791Z","shell.execute_reply":"2024-08-12T06:21:38.379637Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"sentence    Quebec , Canada 's second most populous provin...\nentity1                                                Canada\nentity2                                               Ontario\nlabel               location_country_administrative_divisions\nName: 13, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"# Display the sentences with more than one label\nsentence_label_counts = df.groupby('sentence')['label'].nunique()\n\n# Filter to find sentences that have more than one unique label\nmulti_label_sentences = sentence_label_counts[sentence_label_counts > 1]\n\n\nmulti_label_sentences_list = df[df['sentence'].isin(multi_label_sentences.index)]\nmulti_label_sentences_list.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:21:48.595415Z","iopub.execute_input":"2024-08-12T06:21:48.596185Z","iopub.status.idle":"2024-08-12T06:21:48.795670Z","shell.execute_reply.started":"2024-08-12T06:21:48.596152Z","shell.execute_reply":"2024-08-12T06:21:48.794734Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 47602 entries, 8 to 94221\nData columns (total 4 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   sentence  47602 non-null  object\n 1   entity1   47602 non-null  object\n 2   entity2   47602 non-null  object\n 3   label     47602 non-null  object\ndtypes: object(4)\nmemory usage: 1.8+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define pairs of similar labels\nsimilar_labels_pairs = [\n    ('business_company_major_shareholders', 'business_company_shareholder_major_shareholder_of'),\n    ('location_administrative_division_country', 'location_country_administrative_divisions'),\n    ('sports_sports_team_location', 'sports_sports_team_location_teams')\n]\n\n# Initialize a list to store sentences where these pairs occur\nsentences_with_similar_labels = []\n\n# Loop through each pair and find sentences where both labels are present\nfor label1, label2 in similar_labels_pairs:\n    sentences_with_both_labels = df[df['label'].isin([label1, label2])]['sentence']\n    common_sentences = sentences_with_both_labels.value_counts()[sentences_with_both_labels.value_counts() > 1].index.tolist()\n    sentences_with_similar_labels.extend(common_sentences)\n\n# Remove duplicates from the list\nsentences_with_similar_labels = list(set(sentences_with_similar_labels))\n\n# Display the sentences with the similar labels\nsimilar_label_examples = df[df['sentence'].isin(sentences_with_similar_labels)]\nsimilar_label_examples.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:22:15.838203Z","iopub.execute_input":"2024-08-12T06:22:15.839051Z","iopub.status.idle":"2024-08-12T06:22:15.907375Z","shell.execute_reply.started":"2024-08-12T06:22:15.839018Z","shell.execute_reply":"2024-08-12T06:22:15.906462Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 21214 entries, 11 to 94202\nData columns (total 4 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   sentence  21214 non-null  object\n 1   entity1   21214 non-null  object\n 2   entity2   21214 non-null  object\n 3   label     21214 non-null  object\ndtypes: object(4)\nmemory usage: 828.7+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a dictionary to map old labels to new consolidated labels\nlabel_mapping = {\n    'business_company_shareholder_major_shareholder_of': 'business_company_major_shareholders',\n    'location_country_administrative_divisions': 'location_administrative_division_country',\n    'sports_sports_team_location_teams': 'sports_sports_team_location'\n}\n\n# Apply the mapping to the dataframe\ndf['label'] = df['label'].replace(label_mapping)\n\n# Verify that the labels have been grouped correctly\ndf[df['sentence'].isin(sentences_with_similar_labels)]\n","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:23:00.355685Z","iopub.execute_input":"2024-08-12T06:23:00.356049Z","iopub.status.idle":"2024-08-12T06:23:00.414511Z","shell.execute_reply.started":"2024-08-12T06:23:00.356020Z","shell.execute_reply":"2024-08-12T06:23:00.413652Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                                sentence  \\\n11     Quebec , Canada 's second most populous provin...   \n12     Quebec , Canada 's second most populous provin...   \n13     Quebec , Canada 's second most populous provin...   \n19     A French court sentenced six Algerian-French m...   \n20     A French court sentenced six Algerian-French m...   \n...                                                  ...   \n94198  The United Arab Emirates deserves a serious , ...   \n94199  The United Arab Emirates deserves a serious , ...   \n94200  It 's easy to imagine how the Bush administrat...   \n94201  It 's easy to imagine how the Bush administrat...   \n94202  It 's easy to imagine how the Bush administrat...   \n\n                    entity1               entity2  \\\n11                  Ontario                Canada   \n12                   Canada               Ontario   \n13                   Canada               Ontario   \n19                    Paris                France   \n20                   France                 Paris   \n...                     ...                   ...   \n94198                 Dubai  United Arab Emirates   \n94199  United Arab Emirates                 Dubai   \n94200  United Arab Emirates                 Dubai   \n94201                 Dubai  United Arab Emirates   \n94202  United Arab Emirates                 Dubai   \n\n                                          label  \n11     location_administrative_division_country  \n12                   location_location_contains  \n13     location_administrative_division_country  \n19     location_administrative_division_country  \n20                   location_location_contains  \n...                                         ...  \n94198  location_administrative_division_country  \n94199  location_administrative_division_country  \n94200  location_administrative_division_country  \n94201  location_administrative_division_country  \n94202                location_location_contains  \n\n[21214 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>entity1</th>\n      <th>entity2</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>Quebec , Canada 's second most populous provin...</td>\n      <td>Ontario</td>\n      <td>Canada</td>\n      <td>location_administrative_division_country</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Quebec , Canada 's second most populous provin...</td>\n      <td>Canada</td>\n      <td>Ontario</td>\n      <td>location_location_contains</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Quebec , Canada 's second most populous provin...</td>\n      <td>Canada</td>\n      <td>Ontario</td>\n      <td>location_administrative_division_country</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>A French court sentenced six Algerian-French m...</td>\n      <td>Paris</td>\n      <td>France</td>\n      <td>location_administrative_division_country</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>A French court sentenced six Algerian-French m...</td>\n      <td>France</td>\n      <td>Paris</td>\n      <td>location_location_contains</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>94198</th>\n      <td>The United Arab Emirates deserves a serious , ...</td>\n      <td>Dubai</td>\n      <td>United Arab Emirates</td>\n      <td>location_administrative_division_country</td>\n    </tr>\n    <tr>\n      <th>94199</th>\n      <td>The United Arab Emirates deserves a serious , ...</td>\n      <td>United Arab Emirates</td>\n      <td>Dubai</td>\n      <td>location_administrative_division_country</td>\n    </tr>\n    <tr>\n      <th>94200</th>\n      <td>It 's easy to imagine how the Bush administrat...</td>\n      <td>United Arab Emirates</td>\n      <td>Dubai</td>\n      <td>location_administrative_division_country</td>\n    </tr>\n    <tr>\n      <th>94201</th>\n      <td>It 's easy to imagine how the Bush administrat...</td>\n      <td>Dubai</td>\n      <td>United Arab Emirates</td>\n      <td>location_administrative_division_country</td>\n    </tr>\n    <tr>\n      <th>94202</th>\n      <td>It 's easy to imagine how the Bush administrat...</td>\n      <td>United Arab Emirates</td>\n      <td>Dubai</td>\n      <td>location_location_contains</td>\n    </tr>\n  </tbody>\n</table>\n<p>21214 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"unique_labels = df['label'].unique()\nsorted(unique_labels)\n#21 labels","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:23:18.293511Z","iopub.execute_input":"2024-08-12T06:23:18.293881Z","iopub.status.idle":"2024-08-12T06:23:18.310635Z","shell.execute_reply.started":"2024-08-12T06:23:18.293841Z","shell.execute_reply":"2024-08-12T06:23:18.309700Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"['business_company_advisors',\n 'business_company_founders',\n 'business_company_industry',\n 'business_company_major_shareholders',\n 'business_company_place_founded',\n 'business_person_company',\n 'location_administrative_division_country',\n 'location_country_capital',\n 'location_location_contains',\n 'location_neighborhood_neighborhood_of',\n 'people_deceased_person_place_of_death',\n 'people_ethnicity_geographic_distribution',\n 'people_ethnicity_people',\n 'people_person_children',\n 'people_person_ethnicity',\n 'people_person_nationality',\n 'people_person_place_lived',\n 'people_person_place_of_birth',\n 'people_person_profession',\n 'people_person_religion',\n 'sports_sports_team_location']"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preprocess","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:23:41.747619Z","iopub.execute_input":"2024-08-12T06:23:41.748542Z","iopub.status.idle":"2024-08-12T06:23:46.978641Z","shell.execute_reply.started":"2024-08-12T06:23:41.748506Z","shell.execute_reply":"2024-08-12T06:23:46.977433Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:23:50.803769Z","iopub.execute_input":"2024-08-12T06:23:50.804824Z","iopub.status.idle":"2024-08-12T06:23:50.836156Z","shell.execute_reply.started":"2024-08-12T06:23:50.804792Z","shell.execute_reply":"2024-08-12T06:23:50.835232Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Initialize the tokenizer\ntokenizer = BartTokenizer.from_pretrained('facebook/bart-large', local_files_only=False)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-08-09T14:45:18.415820Z","iopub.execute_input":"2024-08-09T14:45:18.416185Z","iopub.status.idle":"2024-08-09T14:45:19.892958Z","shell.execute_reply.started":"2024-08-09T14:45:18.416150Z","shell.execute_reply":"2024-08-09T14:45:19.891835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1. Preprocess the data\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nlabel_encoder = {label: i for i, label in enumerate(df['label'].unique())}\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:24:45.095823Z","iopub.execute_input":"2024-08-12T06:24:45.096717Z","iopub.status.idle":"2024-08-12T06:24:46.653530Z","shell.execute_reply.started":"2024-08-12T06:24:45.096684Z","shell.execute_reply":"2024-08-12T06:24:46.652739Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b335e3a795847bc9828704d174e5a91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e11febb1950f47e2a63b5546dd92080e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d2f91eb5ef6447c8fefb32f9b7828d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe656b018a054c8497bb0de2c6d01c18"}},"metadata":{}}]},{"cell_type":"code","source":"# Check the maximum length of the tokenized labels\nlabel_lengths = [len(tokenizer.encode(label, add_special_tokens=True)) for label in df['label'].unique()]\nmax_label_length = max(label_lengths)\nprint(f\"Maximum label length: {max_label_length}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:24:52.376040Z","iopub.execute_input":"2024-08-12T06:24:52.376392Z","iopub.status.idle":"2024-08-12T06:24:52.400776Z","shell.execute_reply.started":"2024-08-12T06:24:52.376364Z","shell.execute_reply":"2024-08-12T06:24:52.399930Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Maximum label length: 13\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_data(row):\n    sentence = row['sentence']\n    # Tokenize sentence\n    tokens = tokenizer.tokenize(sentence)\n\n    # Encode entities positions\n    encoded_sentence = tokenizer.encode_plus(\n        sentence,\n        add_special_tokens=True,\n        max_length=128,\n        padding='max_length',\n        truncation=True,\n        return_attention_mask=True,\n        return_tensors='pt'\n    ).to(device)\n\n    return {\n        'input_ids': encoded_sentence['input_ids'].squeeze(),\n        'attention_mask': encoded_sentence['attention_mask'].squeeze(),\n        'label': torch.tensor(label_encoder[row['label']])\n    }","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:27:59.192179Z","iopub.execute_input":"2024-08-12T06:27:59.193048Z","iopub.status.idle":"2024-08-12T06:27:59.199086Z","shell.execute_reply.started":"2024-08-12T06:27:59.193010Z","shell.execute_reply":"2024-08-12T06:27:59.198225Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"#apply preprocess to dataset\ntrain_data = train_df.apply(preprocess_data, axis=1).tolist()\nval_data = val_df.apply(preprocess_data, axis=1).tolist()","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:28:17.016095Z","iopub.execute_input":"2024-08-12T06:28:17.017059Z","iopub.status.idle":"2024-08-12T06:33:21.901651Z","shell.execute_reply.started":"2024-08-12T06:28:17.017013Z","shell.execute_reply":"2024-08-12T06:33:21.900807Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# 2. Create custom dataset class\nclass RelationshipDataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx]","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-12T06:33:47.485523Z","iopub.execute_input":"2024-08-12T06:33:47.485902Z","iopub.status.idle":"2024-08-12T06:33:47.491190Z","shell.execute_reply.started":"2024-08-12T06:33:47.485851Z","shell.execute_reply":"2024-08-12T06:33:47.490330Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Create dataset and dataloader\ntrain_dataset = RelationshipDataset(train_data)\nval_dataset = RelationshipDataset(val_data)\ntrain_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-12T06:34:13.309091Z","iopub.execute_input":"2024-08-12T06:34:13.309439Z","iopub.status.idle":"2024-08-12T06:34:13.314956Z","shell.execute_reply.started":"2024-08-12T06:34:13.309411Z","shell.execute_reply":"2024-08-12T06:34:13.313780Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class RelationshipExtractionModel(torch.nn.Module):\n    def __init__(self, num_labels):\n        #the final layer (classifier of num_labels) that performs the classification is new and \n        # hasn't been trained yet, hence it is \"newly initialized.\"\n        super().__init__()\n        self.bert = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n        \n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        return logits","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:35:11.900049Z","iopub.execute_input":"2024-08-12T06:35:11.900645Z","iopub.status.idle":"2024-08-12T06:35:11.906135Z","shell.execute_reply.started":"2024-08-12T06:35:11.900611Z","shell.execute_reply":"2024-08-12T06:35:11.905239Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.optim.lr_scheduler import StepLR\nfrom sklearn.metrics import accuracy_score\nfrom tqdm.auto import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-08-12T07:11:50.844791Z","iopub.execute_input":"2024-08-12T07:11:50.845604Z","iopub.status.idle":"2024-08-12T07:11:50.849824Z","shell.execute_reply.started":"2024-08-12T07:11:50.845573Z","shell.execute_reply":"2024-08-12T07:11:50.848921Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# 4. Set up training loop\nnum_labels = len(df['label'].unique())\nmodel = RelationshipExtractionModel(num_labels)\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T06:58:07.985133Z","iopub.execute_input":"2024-08-12T06:58:07.985711Z","iopub.status.idle":"2024-08-12T06:58:08.500518Z","shell.execute_reply.started":"2024-08-12T06:58:07.985677Z","shell.execute_reply":"2024-08-12T06:58:08.499751Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Training configuration\nnum_epochs = 5  # Increased number of epochs\nlearning_rate = 2.5e-5","metadata":{"execution":{"iopub.status.busy":"2024-08-12T07:19:13.797625Z","iopub.execute_input":"2024-08-12T07:19:13.797986Z","iopub.status.idle":"2024-08-12T07:19:13.802175Z","shell.execute_reply.started":"2024-08-12T07:19:13.797958Z","shell.execute_reply":"2024-08-12T07:19:13.801305Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T07:16:53.865064Z","iopub.execute_input":"2024-08-12T07:16:53.865420Z","iopub.status.idle":"2024-08-12T07:16:53.877791Z","shell.execute_reply.started":"2024-08-12T07:16:53.865389Z","shell.execute_reply":"2024-08-12T07:16:53.876680Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"RelationshipExtractionModel(\n  (bert): BertForSequenceClassification(\n    (bert): BertModel(\n      (embeddings): BertEmbeddings(\n        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n        (position_embeddings): Embedding(512, 768)\n        (token_type_embeddings): Embedding(2, 768)\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (encoder): BertEncoder(\n        (layer): ModuleList(\n          (0-11): 12 x BertLayer(\n            (attention): BertAttention(\n              (self): BertSdpaSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n      (pooler): BertPooler(\n        (dense): Linear(in_features=768, out_features=768, bias=True)\n        (activation): Tanh()\n      )\n    )\n    (dropout): Dropout(p=0.1, inplace=False)\n    (classifier): Linear(in_features=768, out_features=21, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Optimizer and learning rate scheduler\noptimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\nscheduler = StepLR(optimizer, step_size=3, gamma=0.1)  \n# Reduce LR every 3 epochs by a factor of 0.1","metadata":{"execution":{"iopub.status.busy":"2024-08-12T07:12:45.012582Z","iopub.execute_input":"2024-08-12T07:12:45.013303Z","iopub.status.idle":"2024-08-12T07:12:45.019718Z","shell.execute_reply.started":"2024-08-12T07:12:45.013270Z","shell.execute_reply":"2024-08-12T07:12:45.018638Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# Training Loop","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\n\ndef evaluate(model, dataloader):\n    model.eval()\n    total_preds = []\n    total_labels = []\n    total_val_loss = 0\n\n    with torch.no_grad():\n        for batch in dataloader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n\n            outputs = model(input_ids, attention_mask)\n            loss = torch.nn.functional.cross_entropy(outputs, labels)\n            total_val_loss += loss.item()\n\n            _, preds = torch.max(outputs, dim=1)\n            total_preds.extend(preds.cpu().tolist())\n            total_labels.extend(labels.cpu().tolist())\n\n    avg_val_loss = total_val_loss / len(dataloader)\n    val_accuracy = accuracy_score(total_labels, total_preds)\n    val_f1 = f1_score(total_labels, total_preds, average='weighted')  # or 'macro', 'micro', depending on your needs\n\n    return avg_val_loss, val_accuracy, val_f1","metadata":{"execution":{"iopub.status.busy":"2024-08-12T07:19:25.661002Z","iopub.execute_input":"2024-08-12T07:19:25.661353Z","iopub.status.idle":"2024-08-12T07:19:25.670047Z","shell.execute_reply.started":"2024-08-12T07:19:25.661323Z","shell.execute_reply":"2024-08-12T07:19:25.668879Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    model.train()\n    total_loss = 0\n    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n\n    for batch in progress_bar:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n\n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask)\n        loss = torch.nn.functional.cross_entropy(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        progress_bar.set_postfix({'train_loss': total_loss / (progress_bar.n + 1)})\n\n    # Validation step after each epoch\n    avg_val_loss, val_accuracy, val_f1 = evaluate(model, val_dataloader)\n    print(f\"Epoch {epoch+1}/{num_epochs} completed. Avg Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, Val F1: {val_f1:.4f}\")\n\n    # Step the learning rate scheduler\n    scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2024-08-12T07:19:36.138097Z","iopub.execute_input":"2024-08-12T07:19:36.138448Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Epoch 1/5:   0%|          | 0/4712 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c748bd4684745ce8b433b2bb3d17cd5"}},"metadata":{}},{"name":"stdout","text":"Epoch 1/5 completed. Avg Val Loss: 0.6370, Val Accuracy: 0.7079, Val F1: 0.7037\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2/5:   0%|          | 0/4712 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c6d0768dade4848bc6f892394411e12"}},"metadata":{}},{"name":"stdout","text":"Epoch 2/5 completed. Avg Val Loss: 0.5864, Val Accuracy: 0.7158, Val F1: 0.6995\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3/5:   0%|          | 0/4712 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d22c65252a2484bb07e349702659ad7"}},"metadata":{}},{"name":"stdout","text":"Epoch 3/5 completed. Avg Val Loss: 0.6137, Val Accuracy: 0.7155, Val F1: 0.6963\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4/5:   0%|          | 0/4712 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86a407998b314f4286c105c23a236dad"}},"metadata":{}},{"name":"stdout","text":"Epoch 4/5 completed. Avg Val Loss: 0.5908, Val Accuracy: 0.7146, Val F1: 0.6942\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5/5:   0%|          | 0/4712 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba3f0841357b4194802b06a516d7ba85"}},"metadata":{}}]},{"cell_type":"code","source":"import torch\n\n# Save the model's state dict\nmodel_save_path = \"model.pth\"\ntorch.save(model.state_dict(), model_save_path)\n\nprint(f\"Model saved to {model_save_path}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test","metadata":{}},{"cell_type":"code","source":"from transformers import BartTokenizer, AutoModelForSeq2SeqLM\n\n# Initialize the tokenizer and model\ntokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\nmodel = AutoModelForSeq2SeqLM.from_pretrained('facebook/bart-large')\nmodel.to(device)  # Make sure the model is on the correct device","metadata":{"execution":{"iopub.status.busy":"2024-08-09T14:47:22.368318Z","iopub.status.idle":"2024-08-09T14:47:22.368696Z","shell.execute_reply.started":"2024-08-09T14:47:22.368488Z","shell.execute_reply":"2024-08-09T14:47:22.368503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_relationship(sentence):\n    # Tokenize the input sentence\n    encoded_sentence = tokenizer.encode_plus(\n        sentence,\n        add_special_tokens=True,\n        max_length=128,\n        padding='max_length',\n        truncation=True,\n        return_attention_mask=True,\n        return_tensors='pt'\n    )\n\n    # Move tensors to the appropriate device\n    input_ids = encoded_sentence['input_ids'].to(device)\n    attention_mask = encoded_sentence['attention_mask'].to(device)\n\n    # Generate output using the model (generating a text output that could describe the relationship)\n    with torch.no_grad():\n        outputs = model.generate(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            max_length=128,  # Adjust max_length based on expected output length\n            num_beams=4,    # Beam search for better results, adjust as needed\n            early_stopping=True\n        )\n\n    # Decode the generated tokens to get the predicted relationship\n    predicted_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    \n    return predicted_sentence\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-09T14:47:22.369793Z","iopub.status.idle":"2024-08-09T14:47:22.370137Z","shell.execute_reply.started":"2024-08-09T14:47:22.369969Z","shell.execute_reply":"2024-08-09T14:47:22.369984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example usage:\nsentence = \"IBM is an American multinational technology company headquartered in Armonk\"\npredicted_relationship = predict_relationship(sentence)\nprint(f\"Predicted relationship: {predicted_relationship}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-09T14:47:22.371706Z","iopub.status.idle":"2024-08-09T14:47:22.372086Z","shell.execute_reply.started":"2024-08-09T14:47:22.371906Z","shell.execute_reply":"2024-08-09T14:47:22.371922Z"},"trusted":true},"execution_count":null,"outputs":[]}]}